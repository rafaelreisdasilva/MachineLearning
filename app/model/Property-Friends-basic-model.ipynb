{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instaling packages\n",
    "#!pip install category_encoders\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!unzip arquive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle #Pickling” is the process whereby a Python object hierarchy is converted into a byte stream\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error)\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__  #to use in requeriments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to load the training and test data into pandas DataFrames\n",
    "def load_data(train_path:str, test_path:str) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Loads the train and test data into pandas DataFrames\n",
    "    \"\"\"\n",
    "\n",
    "    train = pd.read_csv(train_path)\n",
    "    \n",
    "    #adding new features to the model\n",
    "    train = train.join(pd.get_dummies(train.sector)).drop(['sector'],axis=1) #placing the \"type\" category in the training set\n",
    "    train = train.join(pd.get_dummies(train.type)).drop(['type'],axis=1)\n",
    "    train['bathroom_ratio'] = train['n_bathroom']/train['n_rooms']\n",
    "    train['household_rooms']=train['n_rooms']/(train['casa']+train['departamento'])\n",
    "    train = train.dropna()\n",
    "    #feature engineering\n",
    "\n",
    "    test = pd.read_csv(test_path)\n",
    "    \n",
    "    #adding new features to the model\n",
    "    test=test.join(pd.get_dummies(test.sector)).drop(['sector'],axis=1)\n",
    "    test = test.join(pd.get_dummies(test.type)).drop(['type'],axis=1)\n",
    "    test['bathroom_ratio'] = test['n_bathroom']/test['n_rooms']\n",
    "    test['household_rooms']=test['n_rooms']/(test['casa']+test['departamento'])\n",
    "    test = test.dropna()\n",
    "  \n",
    "    \n",
    "    return train, test\n",
    "#Load the training and test data\n",
    "train, test = load_data('train.csv', 'test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifing the columns to use for training, the categorical columns, and the target variable:\n",
    "train_cols = [\n",
    "    col for col in train.columns if col not in ['id', 'target']\n",
    "    ]\n",
    "\n",
    "#|categorical_cols = [\"type\", \"sector\"]\n",
    "#categorical_cols = [\"type\"]\n",
    "target           = \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the categorical transformer using TargetEncoder\n",
    "categorical_transformer = TargetEncoder()\n",
    "\n",
    "#Create a ColumnTransformer to apply the categorical transformer to the categorical columns\n",
    "#preprocessor = ColumnTransformer(\n",
    "##    transformers=[\n",
    "#        ('categorical',\n",
    "#          categorical_transformer,\n",
    "#          categorical_cols)\n",
    "#    ])\n",
    "\n",
    "#Defining the steps of the pipeline, including the preprocessor and the model (GradientBoostingRegressor)\n",
    "steps = [\n",
    " #   ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(**{\n",
    "        \"learning_rate\":0.03, #alpha\n",
    "        \"n_estimators\":2500,   #m\n",
    "        \"max_depth\":6,\n",
    "        \"loss\":\"absolute_error\"\n",
    "    }))\n",
    "]\n",
    "#Creating the pipeline using the defined steps\n",
    "pipeline = Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 GradientBoostingRegressor(learning_rate=0.03,\n",
       "                                           loss=&#x27;absolute_error&#x27;, max_depth=6,\n",
       "                                           n_estimators=2500))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 GradientBoostingRegressor(learning_rate=0.03,\n",
       "                                           loss=&#x27;absolute_error&#x27;, max_depth=6,\n",
       "                                           n_estimators=2500))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.03, loss=&#x27;absolute_error&#x27;,\n",
       "                          max_depth=6, n_estimators=2500)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 GradientBoostingRegressor(learning_rate=0.03,\n",
       "                                           loss='absolute_error', max_depth=6,\n",
       "                                           n_estimators=2500))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the pipeline on the training data:\n",
    "pipeline.fit(train[train_cols], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting property valuations for the test data using the trained model:\n",
    "test_predictions = pipeline.predict(test[train_cols])\n",
    "test_target = test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_predictions), type(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "#defining a function to print evaluation metrics:\n",
    "def print_metrics(predictions, target):\n",
    "    print(\"RMSE: \", np.sqrt(mean_squared_error(predictions, target)))\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(predictions, target))\n",
    "    print(\"MAE : \", mean_absolute_error(predictions, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  372.90731094951246\n",
      "MAPE:  0.0007596856171597557\n",
      "MAE :  15.175179419249107\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test_predictions, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_pipeline-0.1.0.pkl','wb') as b:\n",
    "    pickle.dump(pipeline, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' n�o � reconhecido como um comando interno\n",
      "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "!zip -r ./trained_pipeline_model-0.1.0.pkl.zip ./trained_pipeline-0.1.0.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11899.99960352])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(train.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11899.99960352])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train[0:1]))\n",
    "pipeline.predict(train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   net_usable_area  net_area  n_rooms  n_bathroom  latitude  longitude  price  \\\n",
      "0            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "\n",
      "   la reina  las condes  lo barnechea  nunoa  providencia  vitacura  casa  \\\n",
      "0         0           0             0      0            0         1     0   \n",
      "\n",
      "   departamento  bathroom_ratio  household_rooms  \n",
      "0             1               1                4  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11899.99960352])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_usable_area  net_area  n_rooms  n_bathroom  latitude  longitude  price  \\\n",
    "#la reina  las condes  lo barnechea  nunoa  providencia  vitacura   casa  \\\n",
    "#departamento  bathroom_ratio  household_rooms  \n",
    "apicsv = pd.read_csv(\"api.csv\",sep=\",\")\n",
    "print(apicsv)\n",
    "pipeline.predict(apicsv.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11899.99960352])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"trained_pipeline-0.1.0.pkl\",\"rb\") as f:\n",
    "    model = pickle.load(f) #load the model\n",
    "model.predict(apicsv.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m apicsv\u001b[39m=\u001b[39mapicsv\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mpredict(apicsv)\n",
      "File \u001b[1;32mc:\\Users\\Rafae\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:481\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\Rafae\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1798\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1784\u001b[0m     \u001b[39m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m \n\u001b[0;32m   1786\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1798\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1799\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1800\u001b[0m     )\n\u001b[0;32m   1801\u001b[0m     \u001b[39m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\Rafae\\anaconda3\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Rafae\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rafae\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'dict'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
