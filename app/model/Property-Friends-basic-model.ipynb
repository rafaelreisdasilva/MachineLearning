{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some packages that must be installed if they are not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install category_encoders\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!unzip arquive.zip (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle #Pickling” is the process whereby a Python object hierarchy is converted into a byte stream\n",
    "#import warnings\n",
    "\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error)\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__  #to use in requeriments.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I preferred to turn the categorical variables into dummies and created two more columns after noticing a high correlation of bathrooms and room numbers.\n",
    "Additionally, I wanted to see if the room rate per house was highly correlated with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   net_usable_area  net_area  n_rooms  n_bathroom  latitude  longitude  price  \\\n",
      "0            152.0     257.0      3.0         3.0 -33.37940  -70.54470  18500   \n",
      "1            140.0     165.0      4.0         4.0 -33.41135  -70.56977  14500   \n",
      "2            101.0     101.0      4.0         3.0 -33.44154  -70.55704   6522   \n",
      "3             80.0     112.0      1.0         2.0 -33.42486  -70.60868   6100   \n",
      "4            200.0     200.0      3.0         4.0 -33.40490  -70.59450  19000   \n",
      "\n",
      "   la_reina  las_condes  lo_barnechea  nunoa  providencia  vitacura   casa  \\\n",
      "0     False       False         False  False        False      True   True   \n",
      "1     False        True         False  False        False     False  False   \n",
      "2      True       False         False  False        False     False  False   \n",
      "3     False       False         False  False         True     False  False   \n",
      "4     False       False         False  False        False      True  False   \n",
      "\n",
      "   departamento  bathroom_ratio  household_rooms  \n",
      "0         False        1.000000              3.0  \n",
      "1          True        1.000000              4.0  \n",
      "2          True        0.750000              4.0  \n",
      "3          True        2.000000              1.0  \n",
      "4          True        1.333333              3.0  \n"
     ]
    }
   ],
   "source": [
    "#Defining a function to load the training and test data into pandas DataFrames\n",
    "def load_data(train_path:str, test_path:str) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Loads the train and test data into pandas DataFrames\n",
    "    \"\"\"\n",
    "\n",
    "    train = pd.read_csv(train_path)\n",
    "    \n",
    "    #adding new features to the model\n",
    "    train = train.join(pd.get_dummies(train.sector)).drop(['sector'],axis=1) #placing the \"type\" category in the training set\n",
    "    train = train.join(pd.get_dummies(train.type)).drop(['type'],axis=1)\n",
    "    train['bathroom_ratio'] = train['n_bathroom']/train['n_rooms']\n",
    "    train['household_rooms']=train['n_rooms']/(train['casa']+train['departamento'])\n",
    "    train = train.dropna()\n",
    "    \n",
    "    # Mapping dictionary to rename the columns\n",
    "    column_mapping = {\n",
    "        \"net_usable_area\": \"net_usable_area\",\n",
    "        \"net_area\": \"net_area\",\n",
    "        \"n_rooms\": \"n_rooms\",\n",
    "        \"n_bathroom\": \"n_bathroom\",\n",
    "        \"latitude\": \"latitude\",\n",
    "        \"longitude\": \"longitude\",\n",
    "        \"price\": \"price\",\n",
    "        \"la reina\": \"la_reina\",\n",
    "        \"las condes\": \"las_condes\",\n",
    "        \"lo barnechea\": \"lo_barnechea\",\n",
    "        \"nunoa\": \"nunoa\",\n",
    "        \"providencia\": \"providencia\",\n",
    "        \"vitacura\": \"vitacura\",\n",
    "        \"casa\": \"casa\",\n",
    "        \"departamento\": \"departamento\",\n",
    "        \"bathroom_ratio\": \"bathroom_ratio\",\n",
    "        \"household_rooms\": \"household_rooms\"\n",
    "    }\n",
    "\n",
    "    # Renaming the columns\n",
    "    train = train.rename(columns=column_mapping)\n",
    "\n",
    "    #feature engineering\n",
    "\n",
    "    test = pd.read_csv(test_path)\n",
    "    \n",
    "    #adding new features to the model\n",
    "    test=test.join(pd.get_dummies(test.sector)).drop(['sector'],axis=1)\n",
    "    test = test.join(pd.get_dummies(test.type)).drop(['type'],axis=1)\n",
    "    test['bathroom_ratio'] = test['n_bathroom']/test['n_rooms']\n",
    "    test['household_rooms']=test['n_rooms']/(test['casa']+test['departamento'])\n",
    "    test = test.dropna()\n",
    "\n",
    "      # Mapping dictionary to rename the columns\n",
    "    column_mapping = {\n",
    "        \"net_usable_area\": \"net_usable_area\",\n",
    "        \"net_area\": \"net_area\",\n",
    "        \"n_rooms\": \"n_rooms\",\n",
    "        \"n_bathroom\": \"n_bathroom\",\n",
    "        \"latitude\": \"latitude\",\n",
    "        \"longitude\": \"longitude\",\n",
    "        \"price\": \"price\",\n",
    "        \"la reina\": \"la_reina\",\n",
    "        \"las condes\": \"las_condes\",\n",
    "        \"lo barnechea\": \"lo_barnechea\",\n",
    "        \"nunoa\": \"nunoa\",\n",
    "        \"providencia\": \"providencia\",\n",
    "        \"vitacura\": \"vitacura\",\n",
    "        \"casa\": \"casa\",\n",
    "        \"departamento\": \"departamento\",\n",
    "        \"bathroom_ratio\": \"bathroom_ratio\",\n",
    "        \"household_rooms\": \"household_rooms\"\n",
    "    }\n",
    "\n",
    "    # Renaming the columns\n",
    "    test = test.rename(columns=column_mapping)\n",
    "    \n",
    "    return train, test\n",
    "#Load the training and test data\n",
    "train, test = load_data('./learningFiles/train.csv', './learningFiles/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifing the columns to use for training, the categorical columns, and the target variable:\n",
    "train_cols = [\n",
    "    col for col in train.columns if col not in ['id', 'target']\n",
    "    ]\n",
    "\n",
    "#|categorical_cols = [\"type\", \"sector\"]\n",
    "#categorical_cols = [\"type\"]\n",
    "target           = \"price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the categorical transformer using TargetEncoder\n",
    "categorical_transformer = TargetEncoder()\n",
    "\n",
    "#Create a ColumnTransformer to apply the categorical transformer to the categorical columns\n",
    "#preprocessor = ColumnTransformer(\n",
    "##    transformers=[\n",
    "#        ('categorical',\n",
    "#          categorical_transformer,\n",
    "#          categorical_cols)\n",
    "#    ])\n",
    "\n",
    "#Defining the steps of the pipeline, including the preprocessor and the model (GradientBoostingRegressor)\n",
    "steps = [\n",
    " #   ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(**{\n",
    "        \"learning_rate\":0.03, #alpha\n",
    "        \"n_estimators\":2500,   #m\n",
    "        \"max_depth\":6,\n",
    "        \"loss\":\"absolute_error\"\n",
    "    }))\n",
    "]\n",
    "#Creating the pipeline using the defined steps\n",
    "pipeline = Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 GradientBoostingRegressor(learning_rate=0.03,\n",
       "                                           loss=&#x27;absolute_error&#x27;, max_depth=6,\n",
       "                                           n_estimators=2500))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 GradientBoostingRegressor(learning_rate=0.03,\n",
       "                                           loss=&#x27;absolute_error&#x27;, max_depth=6,\n",
       "                                           n_estimators=2500))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.03, loss=&#x27;absolute_error&#x27;,\n",
       "                          max_depth=6, n_estimators=2500)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 GradientBoostingRegressor(learning_rate=0.03,\n",
       "                                           loss='absolute_error', max_depth=6,\n",
       "                                           n_estimators=2500))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the pipeline on the training data:\n",
    "pipeline.fit(train[train_cols], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting property valuations for the test data using the trained model:\n",
    "test_predictions = pipeline.predict(test[train_cols])\n",
    "test_target = test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_predictions), type(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "#defining a function to print evaluation metrics:\n",
    "def print_metrics(predictions, target):\n",
    "    print(\"RMSE: \", np.sqrt(mean_squared_error(predictions, target)))\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(predictions, target))\n",
    "    print(\"MAE : \", mean_absolute_error(predictions, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  236.50304609785385\n",
      "MAPE:  0.0007902052430558677\n",
      "MAE :  12.244290911099439\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test_predictions, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_pipeline-0.1.0.pkl','wb') as b:\n",
    "    pickle.dump(pipeline, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' n�o � reconhecido como um comando interno\n",
      "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "!zip -r ./trained_pipeline_model-0.1.0.pkl.zip ./trained_pipeline-0.1.0.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model idempotency with several different calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11899.99938052])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(train.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11899.99938052])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train[0:1]))\n",
    "pipeline.predict(train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   net_usable_area  net_area  n_rooms  n_bathroom  latitude  longitude  price  \\\n",
      "0            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "1            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "2            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "3            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "4            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "5            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "6            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "7            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "8            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "9            140.0     170.0      4.0         4.0 -33.40123  -70.58056  11900   \n",
      "\n",
      "   la reina  las condes  lo barnechea  nunoa  providencia  vitacura  casa  \\\n",
      "0         0           0             0      0            0         1     0   \n",
      "1         0           0             0      0            0         1     0   \n",
      "2         0           0             0      0            0         1     0   \n",
      "3         0           0             0      0            0         1     0   \n",
      "4         0           0             0      0            0         1     0   \n",
      "5         0           0             0      0            0         1     0   \n",
      "6         0           0             0      0            0         1     0   \n",
      "7         0           0             0      0            0         1     0   \n",
      "8         0           0             0      0            0         1     0   \n",
      "9         0           0             0      0            0         1     0   \n",
      "\n",
      "   departamento  bathroom_ratio  household_rooms  \n",
      "0             1               1                4  \n",
      "1             1               1                4  \n",
      "2             1               1                4  \n",
      "3             1               1                4  \n",
      "4             1               1                4  \n",
      "5             1               1                4  \n",
      "6             1               1                4  \n",
      "7             1               1                4  \n",
      "8             1               1                4  \n",
      "9             1               1                4  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11899.99938052])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_usable_area  net_area  n_rooms  n_bathroom  latitude  longitude  price  \\\n",
    "#la reina  las condes  lo barnechea  nunoa  providencia  vitacura   casa  \\\n",
    "#departamento  bathroom_ratio  household_rooms  \n",
    "apicsv = pd.read_csv(\"./learningFiles/api.csv\",sep=\",\")\n",
    "print(apicsv)\n",
    "pipeline.predict(apicsv.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11899.99938052])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"trained_pipeline-0.1.0.pkl\",\"rb\") as f:\n",
    "    model = pickle.load(f) #load the model\n",
    "model.predict(apicsv.loc[[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
